# Hyperparameter Sweep Scripts

è‡ªåŠ¨åŒ–è„šæœ¬ï¼Œç”¨äºæ¢ç´¢ä¸åŒçš„ SAE è¶…å‚æ•°ç»„åˆï¼ˆexpansion_factor å’Œ kï¼‰ã€‚

## ä¸¤ç§è„šæœ¬

### 1. Pythonè„šæœ¬ï¼ˆæ¨èï¼‰

**ä¼˜ç‚¹**ï¼š
- æ›´çµæ´»çš„é…ç½®
- æ›´å¥½çš„é”™è¯¯å¤„ç†
- æ”¯æŒ dry-run æ¨¡å¼
- è‡ªåŠ¨ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š

**ä½¿ç”¨æ–¹æ³•**ï¼š

```bash
# æŸ¥çœ‹æ‰€æœ‰å®éªŒé…ç½®ï¼ˆä¸å®é™…è¿è¡Œï¼‰
python scripts/hyperparam_sweep.py --dry-run

# è¿è¡Œå®Œæ•´sweep
python scripts/hyperparam_sweep.py

# å¿«é€Ÿæµ‹è¯•ï¼ˆåªè®­ç»ƒå°‘é‡æ ·æœ¬ï¼‰
python scripts/hyperparam_sweep.py --max-examples 1000

# å¤±è´¥åç»§ç»­ï¼ˆä¸åœæ­¢æ•´ä¸ªsweepï¼‰
python scripts/hyperparam_sweep.py --continue-on-error

# ä½¿ç”¨4å¼ GPUè€Œä¸æ˜¯é»˜è®¤çš„8å¼ 
python scripts/hyperparam_sweep.py --gpus 4
```

### 2. Shellè„šæœ¬ï¼ˆç®€å•ï¼‰

**ä¼˜ç‚¹**ï¼š
- æ— éœ€Pythonä¾èµ–
- æ›´ç›´è§‚ï¼Œæ˜“äºç†è§£å’Œä¿®æ”¹

**ä½¿ç”¨æ–¹æ³•**ï¼š

```bash
bash scripts/simple_sweep.sh
```

## é…ç½®è¶…å‚æ•°

### Pythonè„šæœ¬é…ç½®

ç¼–è¾‘ `scripts/hyperparam_sweep.py` ä¸­çš„é…ç½®éƒ¨åˆ†ï¼š

```python
# è¦æ‰«æçš„è¶…å‚æ•°
SWEEP_PARAMS = {
    "expansion_factor": [4, 8, 16],      # ä¿®æ”¹è¿™é‡Œ
    "k": [16, 24, 32, 40, 48, 64],       # ä¿®æ”¹è¿™é‡Œ
}

# æ¯ä¸ªå®éªŒè®­ç»ƒçš„tokenæ•°
BASE_CONFIG = {
    ...
    "max_tokens": 100_000_000,  # 100M tokens
    ...
}
```

### Shellè„šæœ¬é…ç½®

ç¼–è¾‘ `scripts/simple_sweep.sh` çš„å¼€å¤´éƒ¨åˆ†ï¼š

```bash
# Hyperparameter grids
EXPANSION_FACTORS=(4 8 16)              # ä¿®æ”¹è¿™é‡Œ
K_VALUES=(16 24 32 40 48 64)            # ä¿®æ”¹è¿™é‡Œ
MAX_TOKENS=100000000                    # ä¿®æ”¹è¿™é‡Œ
```

## å®éªŒè®¾è®¡å»ºè®®

### å¿«é€Ÿæ‰«æï¼ˆæ¢ç´¢é˜¶æ®µï¼‰

```python
SWEEP_PARAMS = {
    "expansion_factor": [4, 8, 16],
    "k": [16, 32, 64],                   # ç²—ç²’åº¦
}
BASE_CONFIG["max_tokens"] = 10_000_000  # 10M tokens
```

é¢„è®¡æ—¶é—´ï¼š~9ä¸ªå®éªŒ

### ç»†ç²’åº¦æ‰«æï¼ˆä¼˜åŒ–é˜¶æ®µï¼‰

å‡è®¾å‘ç° expansion_factor=8 æœ€å¥½ï¼Œç»†åŒ– k çš„æœç´¢ï¼š

```python
SWEEP_PARAMS = {
    "expansion_factor": [8],             # å›ºå®šæœ€ä¼˜å€¼
    "k": [24, 28, 32, 36, 40],          # ç»†ç²’åº¦æ‰«æ
}
BASE_CONFIG["max_tokens"] = 100_000_000  # 100M tokens
```

é¢„è®¡æ—¶é—´ï¼š~5ä¸ªå®éªŒ

### å®Œæ•´è®­ç»ƒï¼ˆæœ€ç»ˆéªŒè¯ï¼‰

```python
SWEEP_PARAMS = {
    "expansion_factor": [8],
    "k": [32],                           # å·²ç¡®å®šçš„æœ€ä¼˜å€¼
}
BASE_CONFIG["max_tokens"] = 1_000_000_000  # 1B tokens
```

## ç›‘æ§å’Œåˆ†æ

### å®æ—¶ç›‘æ§

è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¯ä»¥é€šè¿‡ WandB å®æ—¶æŸ¥çœ‹æ‰€æœ‰å®éªŒï¼š

```bash
# æ‰“å¼€WandBé¡¹ç›®
# æ‰€æœ‰å®éªŒä¼šä»¥ "sweep_ef{N}_k{M}" å‘½å
```

### ç»“æœå¯¹æ¯”

åœ¨ WandB ä¸­ï¼š
1. é€‰æ‹©æ‰€æœ‰ `sweep_` å¼€å¤´çš„runs
2. ç‚¹å‡» "Compare" æŸ¥çœ‹å¹¶æ’å¯¹æ¯”
3. å…³é”®æŒ‡æ ‡ï¼š
   - `fvu`: é‡å»ºæŸå¤±ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
   - `dead_features_ratio`: æ­»ç‰¹å¾æ¯”ä¾‹ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
   - `l0`: å®é™…æ¿€æ´»çš„ç‰¹å¾æ•°ï¼ˆåº”è¯¥â‰ˆkï¼‰

### ç”ŸæˆæŠ¥å‘Š

```bash
# Pythonè„šæœ¬ä¼šåœ¨ç»“æŸæ—¶è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦
# Shellè„šæœ¬ä¼šç”Ÿæˆæ—¥å¿—æ–‡ä»¶
ls sweep_*.log
```

## å¸¸è§ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šé¦–æ¬¡æ¢ç´¢

ä¸ç¡®å®šå“ªäº›è¶…å‚æ•°å¥½ï¼Œè¿›è¡Œå…¨é¢æ‰«æï¼š

```bash
# ç¼–è¾‘ hyperparam_sweep.py:
SWEEP_PARAMS = {
    "expansion_factor": [4, 8, 16, 32],
    "k": [16, 32, 64, 128],
}
BASE_CONFIG["max_tokens"] = 50_000_000  # 50M tokens

# è¿è¡Œ
python scripts/hyperparam_sweep.py
```

### åœºæ™¯2ï¼šåŸºäºä½ çš„å‘ç°

ä½ å·²ç»å‘ç° k=32 æ¯” k=64 å¥½ï¼Œæƒ³è¿›ä¸€æ­¥ç»†åŒ–ï¼š

```bash
# ç¼–è¾‘é…ç½®:
SWEEP_PARAMS = {
    "expansion_factor": [8],  # ä¿æŒç°æœ‰é…ç½®
    "k": [20, 24, 28, 32, 36, 40],  # åœ¨32é™„è¿‘ç»†æœ
}
BASE_CONFIG["max_tokens"] = 100_000_000  # 100M tokens

# è¿è¡Œ
python scripts/hyperparam_sweep.py
```

### åœºæ™¯3ï¼šå¿«é€ŸéªŒè¯

åªæƒ³å¿«é€Ÿæµ‹è¯•è„šæœ¬æ˜¯å¦å·¥ä½œï¼š

```bash
# ä½¿ç”¨å¾ˆå°‘çš„æ•°æ®
python scripts/hyperparam_sweep.py --max-examples 100 --dry-run  # å…ˆé¢„è§ˆ
python scripts/hyperparam_sweep.py --max-examples 100  # å®é™…è¿è¡Œ
```

## ä¸­æ–­å’Œæ¢å¤

### å¦‚æœsweepä¸­é€”ä¸­æ–­ï¼š

1. **Pythonè„šæœ¬**ï¼š
   - ä½¿ç”¨ `--continue-on-error` å¯ä»¥åœ¨å•ä¸ªå®éªŒå¤±è´¥åç»§ç»­
   - å¦‚æœæ•´ä¸ªè„šæœ¬ä¸­æ–­ï¼Œéœ€è¦æ‰‹åŠ¨ç¼–è¾‘ `SWEEP_PARAMS` ç§»é™¤å·²å®Œæˆçš„é…ç½®

2. **Shellè„šæœ¬**ï¼š
   - è„šæœ¬ä¼šè¯¢é—®æ˜¯å¦ç»§ç»­
   - å¯ä»¥æ‰‹åŠ¨ç¼–è¾‘è„šæœ¬ä¸­çš„æ•°ç»„ï¼Œç§»é™¤å·²å®Œæˆçš„é…ç½®

### æ¢å¤ç­–ç•¥ï¼š

```python
# å¦‚æœå·²ç»å®Œæˆ ef=4,8 çš„æ‰€æœ‰å®éªŒï¼Œåªæƒ³ç»§ç»­ ef=16:
SWEEP_PARAMS = {
    "expansion_factor": [16],  # åªä¿ç•™æœªå®Œæˆçš„
    "k": [16, 24, 32, 40, 48, 64],
}
```

## æ³¨æ„äº‹é¡¹

1. **ç«¯å£å†²çª**ï¼šè„šæœ¬ä¼šè‡ªåŠ¨é€’å¢ç«¯å£å·é¿å…å†²çª
2. **ç£ç›˜ç©ºé—´**ï¼šæ¯ä¸ªå®éªŒä¼šä¿å­˜checkpointsï¼Œæ³¨æ„ç£ç›˜ç©ºé—´
3. **æ—¶é—´ä¼°ç®—**ï¼š
   - 10M tokens â‰ˆ 10-20åˆ†é’Ÿï¼ˆå–å†³äºç¡¬ä»¶ï¼‰
   - 100M tokens â‰ˆ 1-2å°æ—¶
   - 1B tokens â‰ˆ 10-20å°æ—¶

4. **GPUå†…å­˜**ï¼šå¦‚æœOOMï¼Œå¯ä»¥å‡å°‘ `batch_size` æˆ–å¢åŠ  `grad_acc_steps`

## ç¤ºä¾‹è¾“å‡º

```
================================================================================
Hyperparameter Sweep Configuration
================================================================================
Total experiments: 18
Sweep parameters:
  - expansion_factor: [4, 8, 16]
  - k: [16, 24, 32, 40, 48, 64]
GPUs per experiment: 8
Tokens per experiment: 100,000,000
================================================================================

Start sweep? [y/N]: y

################################################################################
# Experiment 1/18
################################################################################

Experiment: sweep_ef4_k16_1219_2230
Parameters: expansion_factor=4, k=16
Command: torchrun --nproc_per_node=8 ...

[è®­ç»ƒè¾“å‡º...]

âœ“ Reached target token count: 100,000,064 / 100,000,000
âœ“ Experiment completed successfully in 87.3 minutes

...

================================================================================
Sweep Summary
================================================================================
Completed: 18/18
Successful: 17
Failed: 1

Results:
  âœ“ sweep_ef4_k16_1219_2230 (ef=4, k=16)
  âœ“ sweep_ef4_k24_1219_2318 (ef=4, k=24)
  ...
  âœ— sweep_ef16_k64_1220_0342 (ef=16, k=64)

ğŸ’¡ Tip: Compare runs in WandB:
   1. Go to your WandB project
   2. Select all runs starting with 'sweep_'
   3. Click 'Compare' to see side-by-side metrics
================================================================================
```

## æ•…éšœæ’é™¤

### é—®é¢˜ï¼šCUDA OOM

**è§£å†³**ï¼šå‡å°‘batch sizeæˆ–å¢åŠ gradient accumulation

```python
BASE_CONFIG["batch_size"] = 1  # å·²ç»æ˜¯æœ€å°
BASE_CONFIG["grad_acc_steps"] = 16  # ä»8å¢åŠ åˆ°16
```

### é—®é¢˜ï¼šç«¯å£å†²çª

**è§£å†³**ï¼šè„šæœ¬ä¼šè‡ªåŠ¨é€’å¢ç«¯å£ï¼Œå¦‚æœä»æœ‰å†²çªï¼Œä¿®æ”¹èµ·å§‹ç«¯å£

```python
MASTER_PORT = 29600  # ä½¿ç”¨ä¸åŒçš„èµ·å§‹ç«¯å£
```

### é—®é¢˜ï¼šæ•°æ®åŠ è½½æ…¢

**è§£å†³**ï¼šå¢åŠ data preprocessingè¿›ç¨‹æ•°

```python
BASE_CONFIG["data_preprocessing_num_proc"] = 16  # ä»8å¢åŠ 
```
