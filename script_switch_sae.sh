torchrun --nproc_per_node 1 --master_port 29501 -m sparsify \
    ~/models/Qwen3-8B/ \
    ~/fineweb-edu/sample/10BT \
    --split "train" \
    --wandb_project 'sparsify_sweep_1222_switch' \
    --ctx_len 2048 \
    --max_examples 1000000 \
    --text_column "text" \
    --shuffle_seed 42 \
    --data_preprocessing_num_proc 8 \
    --activation "topk" \
    --expansion_factor 32 \
    --normalize_decoder True \
    --num_latents 0 \
    -k 32 \
    --multi_topk False \
    --skip_connection False \
    --hookpoints "layers.0.self_attn.o_proj" \
    --hook_mode input \
    --init_seeds 0 \
    --batch_size 1 \
    --grad_acc_steps 8 \
    --micro_acc_steps 1 \
    --loss_fn "fvu" \
    --optimizer "signum" \
    --lr 5e-3 \
    --auxk_alpha 0.03125 \
    --dead_feature_threshold 10000000 \
    --save_every 100000 \
    --save_best True \
    --save_dir "checkpoints" \
    --run_name "qwen3-8b-switch-sae-test" \
    --log_to_wandb True \
    --wandb_log_frequency 1 \
    --elbow_threshold_path ~/sparsify/thresholds.json \
    --max_tokens 10000000 \
    --exceed_alphas 0.05 0.10 0.20 0.50 1.0 2.0 \
    --use_switch_sae \
    --num_experts 8 \
    --load_balance_alpha 0.01